{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86bf73b7-9a7b-460b-b582-5c4e45235467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mohad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mohad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def read_text(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def tokenize_sentences(text):\n",
    "    return sent_tokenize(text)\n",
    "\n",
    "def tokenize_words(sentence):\n",
    "    return word_tokenize(sentence)\n",
    "\n",
    "def sentence_similarity(sent1, sent2, stopwords):\n",
    "    words1 = [word.lower() for word in sent1 if word.isalnum() and word.lower() not in stopwords]\n",
    "    words2 = [word.lower() for word in sent2 if word.isalnum() and word.lower() not in stopwords]\n",
    "\n",
    "    all_words = list(set(words1 + words2))\n",
    "\n",
    "    vector1 = [1 if word in words1 else 0 for word in all_words]\n",
    "    vector2 = [1 if word in words2 else 0 for word in all_words]\n",
    "\n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    "\n",
    "def build_similarity_matrix(sentences, stopwords):\n",
    "    matrix = np.zeros((len(sentences), len(sentences)))\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i != j:\n",
    "                matrix[i][j] = sentence_similarity(sentences[i], sentences[j], stopwords)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def generate_summary(document_text, context_window_size, style_text=None):\n",
    "    sentences = tokenize_sentences(document_text)\n",
    "    stopwords_list = set(stopwords.words('english'))\n",
    "\n",
    "    # Measure the length of the document\n",
    "    document_length = len(tokenize_words(document_text))\n",
    "\n",
    "    # Compute target lengths in a proportional way\n",
    "    target_lengths = [int(len(sentences) * (len(sentence) / document_length)) for sentence in sentences]\n",
    "\n",
    "    # Slice the document and generate summaries\n",
    "    summary = \"\"\n",
    "    for i in range(len(sentences)):\n",
    "        slice_start = 0 if i == 0 else int(sum(target_lengths[:i]))\n",
    "        slice_end = int(sum(target_lengths[:i + 1]))\n",
    "        slice_end = min(slice_end, len(sentences))  # Ensure not to go beyond the document length\n",
    "\n",
    "        # Slice the document\n",
    "        sliced_document = ' '.join(sentences[slice_start:slice_end])\n",
    "\n",
    "        # Summarize the slice\n",
    "        slice_summary = extractive_summarization(sliced_document, stopwords_list)\n",
    "\n",
    "        # Collate the summaries\n",
    "        summary += slice_summary\n",
    "\n",
    "    # Repeat shrinking activities until the summary size is within the context window\n",
    "    while len(tokenize_words(summary)) > context_window_size:\n",
    "        summary = extractive_summarization(summary, stopwords_list)\n",
    "\n",
    "    # Save the document (you can save the summary to a file if needed)\n",
    "    with open('summary.txt', 'w', encoding='utf-8') as file:\n",
    "        file.write(summary)\n",
    "\n",
    "    # Repeat the summarization for the second document (if needed)\n",
    "    if style_text:\n",
    "        style_summary = extractive_summarization(style_text, stopwords_list)\n",
    "        summary += style_summary\n",
    "\n",
    "    # Generate the query\n",
    "    query = generate_query(summary)\n",
    "\n",
    "    return summary, query\n",
    "\n",
    "def extractive_summarization(text, stopwords_list):\n",
    "    sentences = tokenize_sentences(text)\n",
    "    sentence_matrix = build_similarity_matrix(sentences, stopwords_list)\n",
    "\n",
    "    # Rank sentences based on similarity matrix\n",
    "    sentence_ranks = np.sum(sentence_matrix, axis=1)\n",
    "\n",
    "    # Sort sentences by rank\n",
    "    ranked_sentences = [sentences[i] for i in np.argsort(sentence_ranks)[::-1]]\n",
    "\n",
    "    # Select top sentences for the summary (you can adjust the summary length as needed)\n",
    "    summary_length = int(len(sentences) * 0.3)\n",
    "    summary = ' '.join(ranked_sentences[:summary_length])\n",
    "\n",
    "    return summary\n",
    "\n",
    "def generate_query(summary):\n",
    "    # Placeholder for query generation logic\n",
    "    query = \"Please provide relevant information about:\\n\" + summary\n",
    "    return query\n",
    "\n",
    "# Example usage:\n",
    "document_path = r'C:\\Users\\mohad\\Downloads\\SECTION 2 – SELECTION PROCEDURE .txt'\n",
    "context_window_size = 128  # You can adjust this based on your requirements\n",
    "document_text = read_text(document_path)\n",
    "\n",
    "# Optional: Style text (provide another text for style transfer, if needed)\n",
    "style_text = read_text(r'C:\\Users\\mohad\\Downloads\\CDCL Algorithm Report.txt')  # Replace 'style_text.txt' with the path to your style text file\n",
    "\n",
    "#Generate summary and query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d3fe5bc-8ef7-4040-be2b-87240e5118d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary:\n",
      " If the identity document does not have \n",
      "an English translation, a copy of your passport must be attached.If, due to organisational requirements and/or mandatory provisions, the required adaptation cannot be granted, \n",
      "an alternative measure of equal compensatory value will be defined.Applications:\n",
      "This implementation can be applied to solve SAT problems in artificial intelligence, programming, and circuit design. CDCL Algorithm Report\n",
      "Introduction:\n",
      "The Conflict-Driven Clause Learning (CDCL) algorithm stands out as a powerful method for solving Boolean Satisfiability (SAT) problems. Interesting Points:\n",
      "•\tThe CDCL algorithm was highly efficient in solving SAT problems with special structures, such as Horn chains. Things to Discuss:\n",
      "•\tSuggestions for improving the implementation. The current implementation serves as a solid foundation for future algorithm development and improvement. The main function, designed to receive user input, convert it into statements, call the solver, and print the result, promotes user interaction with the program. The use of the 1UIP heuristic notably improved algorithm performance. •\tIf the problem cannot be solved, the algorithm prints a proof of non-satisfaction. Suggestions for Future Research:\n",
      "•\tInvestigate the performance of the CDCL algorithm on larger and more complex datasets. Main Functions:\n",
      "The key functions of the program include sentence addition, conflict detection, application of the first assertion clause heuristic, backtracking, new sentence learning, variable assignment, information dissemination, and decision-making. Relationships:\n",
      "These tests were conducted on a limited dataset of SAT problems, and results may vary for different collections. This report delves into the implementation details of a simplified version of the CDCL algorithm, showcasing its application in solving propositional logic problems. •\tDevelop new and more efficient algorithms for solving SAT problems.\n",
      "\n",
      "Generated Query:\n",
      " Please provide relevant information about:\n",
      "If the identity document does not have \n",
      "an English translation, a copy of your passport must be attached.If, due to organisational requirements and/or mandatory provisions, the required adaptation cannot be granted, \n",
      "an alternative measure of equal compensatory value will be defined.Applications:\n",
      "This implementation can be applied to solve SAT problems in artificial intelligence, programming, and circuit design. CDCL Algorithm Report\n",
      "Introduction:\n",
      "The Conflict-Driven Clause Learning (CDCL) algorithm stands out as a powerful method for solving Boolean Satisfiability (SAT) problems. Interesting Points:\n",
      "•\tThe CDCL algorithm was highly efficient in solving SAT problems with special structures, such as Horn chains. Things to Discuss:\n",
      "•\tSuggestions for improving the implementation. The current implementation serves as a solid foundation for future algorithm development and improvement. The main function, designed to receive user input, convert it into statements, call the solver, and print the result, promotes user interaction with the program. The use of the 1UIP heuristic notably improved algorithm performance. •\tIf the problem cannot be solved, the algorithm prints a proof of non-satisfaction. Suggestions for Future Research:\n",
      "•\tInvestigate the performance of the CDCL algorithm on larger and more complex datasets. Main Functions:\n",
      "The key functions of the program include sentence addition, conflict detection, application of the first assertion clause heuristic, backtracking, new sentence learning, variable assignment, information dissemination, and decision-making. Relationships:\n",
      "These tests were conducted on a limited dataset of SAT problems, and results may vary for different collections. This report delves into the implementation details of a simplified version of the CDCL algorithm, showcasing its application in solving propositional logic problems. •\tDevelop new and more efficient algorithms for solving SAT problems.\n"
     ]
    }
   ],
  
